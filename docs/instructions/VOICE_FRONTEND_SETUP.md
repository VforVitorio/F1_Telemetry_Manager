# Voice Chat Frontend Setup

Frontend implementation for voice chat in Streamlit with dual-mode support.

## üì¶ Installation

### 1. Install Dependencies

```bash
cd frontend
pip install -r requirements.txt
```

**New dependency installed:**
- `audio-recorder-streamlit==0.0.10` - Audio recording component for Streamlit

### 2. Verify Installation

```bash
python -c "import audio_recorder_streamlit; print('‚úÖ Audio recorder installed')"
```

## üé® Architecture

### New Files Created

```
frontend/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ voice_api.py              # Voice API client (NEW)
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îî‚îÄ‚îÄ audio_utils.py             # Audio utilities (NEW)
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îî‚îÄ‚îÄ voice/                     # Voice components (NEW)
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ voice_input.py         # Voice input UI
‚îÇ       ‚îî‚îÄ‚îÄ voice_chat.py          # Voice chat interface
‚îî‚îÄ‚îÄ pages/
    ‚îî‚îÄ‚îÄ chat.py                    # Modified: added voice mode toggle
```

### Modified Files

- `frontend/pages/chat.py` - Added voice/text mode toggle
- `frontend/requirements.txt` - Added audio-recorder-streamlit

## üöÄ Usage

### Start Frontend

```bash
cd frontend
streamlit run app/main.py
```

Access at: `http://localhost:8501`

### Using Voice Chat

1. Navigate to the **Chat** page
2. Toggle to **üé§ Voice Chat** mode (radio button at top)
3. Click the **microphone** button to start recording
4. Speak your question
5. Click again to **stop recording**
6. Click **üöÄ Send Voice Message**
7. Wait for transcription ‚Üí AI processing ‚Üí speech synthesis
8. Audio response will auto-play

## üéØ Features

### Voice Chat Mode
- ‚úÖ Audio recording with visual feedback
- ‚úÖ Real-time transcription display
- ‚úÖ AI response generation
- ‚úÖ Text-to-speech synthesis
- ‚úÖ Audio playback controls
- ‚úÖ Voice chat history
- ‚úÖ Processing time display
- ‚úÖ Clear history option

### Text Chat Mode
- ‚úÖ Traditional text chat (original functionality)
- ‚úÖ Multimodal support (text + images)
- ‚úÖ Chat history management
- ‚úÖ Context-aware responses

## üìã Component Details

### 1. `voice_api.py` (Services)

API client for backend voice endpoints:

```python
# Functions available:
- check_voice_health() ‚Üí Dict        # Health check
- get_available_voices() ‚Üí List      # List TTS voices
- transcribe_audio() ‚Üí Dict          # STT (audio ‚Üí text)
- synthesize_speech() ‚Üí bytes        # TTS (text ‚Üí audio)
- voice_chat() ‚Üí Dict                # Full flow
- decode_audio_base64() ‚Üí bytes      # Base64 decoder
```

### 2. `audio_utils.py` (Utils)

Audio processing utilities:

```python
# Functions available:
- validate_audio_file()              # Validate format/size
- encode_audio_to_base64()           # Encode audio
- decode_audio_from_base64()         # Decode audio
- get_audio_duration_estimate()      # Estimate duration
- format_duration()                  # Format time string
- create_audio_data_url()            # Create data URL
- get_mime_type_from_filename()      # Get MIME type
```

### 3. `voice_input.py` (Component)

Voice input UI component:

```python
# Functions:
- render_voice_input()               # Main input widget
- render_voice_status()              # Status indicator
- render_voice_controls()            # Control buttons
```

### 4. `voice_chat.py` (Component)

Main voice chat interface:

```python
# Functions:
- initialize_voice_state()           # Initialize state
- add_voice_exchange()               # Add to history
- render_voice_exchange()            # Render single exchange
- render_voice_history()             # Render full history
- handle_voice_message()             # Process voice message
- check_voice_services()             # Check services
- render_voice_chat()                # Main render function
```

### 5. Modified `chat.py`

Added dual-mode support:

```python
# New functions:
- initialize_chat_mode()             # Initialize mode state
- render_header()                    # Header with toggle (modified)
- render_chat_page()                 # Main page (modified)
```

## üîß Code Quality

All code follows clean code principles:

- ‚úÖ **Single Responsibility**: Each function does one thing
- ‚úÖ **Small Functions**: 15-30 lines max
- ‚úÖ **Type Hints**: All functions have type annotations
- ‚úÖ **Docstrings**: Complete documentation
- ‚úÖ **Error Handling**: Graceful error management
- ‚úÖ **Consistent Style**: Follows existing codebase patterns

## üß™ Testing the Frontend

### 1. Test Voice Services Connection

Navigate to Voice Chat mode. You should see:
- ‚úÖ Green status if services are ready
- ‚ùå Error message if backend is not running

### 2. Test Audio Recording

Click the microphone:
- üî¥ Red = Recording
- üîµ Blue = Ready
- Shows recording size in bytes

### 3. Test Voice Chat Flow

1. Record a question: "What was Verstappen's fastest lap time?"
2. Should see:
   - "üîÑ Transcribing audio..."
   - "ü§ñ AI is thinking..."
   - "üîä Generating speech..."
   - "‚úÖ Voice message processed!"
3. Audio response auto-plays
4. Exchange appears in history

### 4. Test Mode Toggle

Switch between modes:
- üí¨ Text Chat ‚Üí Original chat interface
- üé§ Voice Chat ‚Üí Voice interface
- State is preserved when switching

## üêõ Troubleshooting

### Issue: "audio-recorder-streamlit not found"

```bash
pip install audio-recorder-streamlit==0.0.10
```

### Issue: Microphone not working

**Browser permissions:**
1. Check browser allows microphone access
2. Allow permissions for localhost:8501

**Windows:**
1. Settings > Privacy > Microphone
2. Enable microphone for browsers

### Issue: "Voice services not available"

Ensure backend is running:
```bash
cd backend
uvicorn main:app --reload --port 8000
```

Check health endpoint:
```bash
curl http://localhost:8000/api/v1/voice/health
```

### Issue: No audio playback

Check browser audio settings:
- Volume not muted
- Audio output device selected
- Try different browser

## üìä Performance

Expected response times:
- **Transcription**: 2-5 seconds (depends on audio length)
- **LLM Response**: 3-8 seconds (depends on question complexity)
- **Speech Synthesis**: 1-3 seconds (depends on text length)
- **Total**: ~6-16 seconds end-to-end

## üéØ Next Steps

1. ‚úÖ Frontend MVP complete
2. ‚è≠Ô∏è **Next**: Integrate with LM Studio in voice chat flow
3. ‚è≠Ô∏è **After**: Add ChatGPT-style orb visualization (Phase 3)
4. ‚è≠Ô∏è **Future**: Voice activity detection (VAD) for auto-stop
5. ‚è≠Ô∏è **Future**: Wake word detection ("Hey Caronte")

## üîó Related Documentation

- [Backend Voice Setup](../backend/VOICE_SETUP.md)
- [Backend Installation](../backend/INSTALL_INSTRUCTIONS.md)
- [Voice Implementation Plan](../docs/VOICE_CHAT_IMPLEMENTATION_PLAN.md)

## ‚úÖ Summary

**Frontend voice chat is now complete!**

- ‚úÖ 5 new files created
- ‚úÖ 2 files modified
- ‚úÖ Clean code principles applied
- ‚úÖ Full dual-mode support (text + voice)
- ‚úÖ Ready for testing

**To use:**
1. Install dependencies: `pip install -r requirements.txt`
2. Start backend: `uvicorn main:app --reload`
3. Start frontend: `streamlit run app/main.py`
4. Navigate to Chat page
5. Toggle to üé§ Voice Chat mode
6. Start talking!
